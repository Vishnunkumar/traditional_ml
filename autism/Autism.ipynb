{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding Autism in ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split as tts\n",
    "import sklearn.metrics as met"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')\n",
    "df.drop(['Case_No'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for class imbalance if its there we have to chose a different metric/ or do class balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    728\n",
       "0    326\n",
       "Name: Class/ASD Traits , dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Class/ASD Traits '].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A1                         int64\n",
       "A2                         int64\n",
       "A3                         int64\n",
       "A4                         int64\n",
       "A5                         int64\n",
       "A6                         int64\n",
       "A7                         int64\n",
       "A8                         int64\n",
       "A9                         int64\n",
       "A10                        int64\n",
       "Age_Mons                   int64\n",
       "Qchat-10-Score             int64\n",
       "Sex                       object\n",
       "Ethnicity                 object\n",
       "Jaundice                  object\n",
       "Family_mem_with_ASD       object\n",
       "Who completed the test    object\n",
       "Class/ASD Traits          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A1                        0\n",
       "A2                        0\n",
       "A3                        0\n",
       "A4                        0\n",
       "A5                        0\n",
       "A6                        0\n",
       "A7                        0\n",
       "A8                        0\n",
       "A9                        0\n",
       "A10                       0\n",
       "Age_Mons                  0\n",
       "Qchat-10-Score            0\n",
       "Sex                       0\n",
       "Ethnicity                 0\n",
       "Jaundice                  0\n",
       "Family_mem_with_ASD       0\n",
       "Who completed the test    0\n",
       "Class/ASD Traits          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing label and one-hot encoding of the string variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre(d_f):\n",
    "    \"\"\"\n",
    "    Function returns pre-processed data for training\n",
    "    \"\"\"\n",
    "    \n",
    "    lab = LabelEncoder()\n",
    "    d_f['Sex'] = lab.fit_transform(d_f['Sex'])\n",
    "    d_f['Ethnicity'] = lab.fit_transform(d_f['Ethnicity'])\n",
    "    d_f['Jaundice'] = lab.fit_transform(d_f['Jaundice'])\n",
    "    d_f['Family_mem_with_ASD'] = lab.fit_transform(d_f['Family_mem_with_ASD'])\n",
    "    d_f['Who completed the test'] = lab.fit_transform(d_f['Who completed the test'])\n",
    "    d_f['Class/ASD Traits '] = lab.fit_transform(d_f['Class/ASD Traits '])\n",
    "    \n",
    "    c_c = ['Ethnicity', 'Who completed the test']\n",
    "    me = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "    me.fit(d_f[c_c])\n",
    "    df_new_ = pd.concat([d_f.drop(c_c, 1), pd.DataFrame(myEncoder.transform(d_f[c_c]))], axis=1).reindex()\n",
    "    \n",
    "    return df_new_\n",
    "\n",
    "df_tr = pre(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr_x = df_tr.drop(['Class/ASD Traits '],1)\n",
    "df_tr_y = df_tr['Class/ASD Traits ']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_x, te_x, tr_y, te_y = tts(df_tr_x, df_tr_y, train_size=.8, random_state=277)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = LogisticRegression()\n",
    "model = log.fit(tr_x,tr_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(te_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 59,   4],\n",
       "       [  0, 148]])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "met.confusion_matrix(te_y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_1 = met.f1_score(te_y, pred)\n",
    "prec_ = met.f1_score(te_y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['A1', 'A2', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8', 'A9', 'A10', 'Age_Mons',\n",
       "       'Qchat-10-Score', 'Sex', 'Ethnicity', 'Jaundice', 'Family_mem_with_ASD',\n",
       "       'Who completed the test', 'Class/ASD Traits '],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction of values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,1,1,1,1,1,1,0,1,1,28,9,m,middle eastern,no,no,family member\n"
     ]
    }
   ],
   "source": [
    "def get_input():\n",
    "    \"\"\"\n",
    "    Returns processed form of input for prediction\n",
    "    \"\"\"\n",
    "    in_ = input()\n",
    "    in_ = in_.split(',')\n",
    "    num_ = [float(x) for x in in_ if in_.index(x) < 12]\n",
    "    in_ = num_ + in_[12:]\n",
    "    return in_\n",
    "inp_ = get_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_pd(d_f):\n",
    "    \"\"\"\n",
    "    Function returns pre-processed data for training\n",
    "    \"\"\"\n",
    "    \n",
    "    lab = LabelEncoder()\n",
    "    d_f['Sex'] = lab.fit_transform(d_f['Sex'])\n",
    "    d_f['Ethnicity'] = lab.fit_transform(d_f['Ethnicity'])\n",
    "    d_f['Jaundice'] = lab.fit_transform(d_f['Jaundice'])\n",
    "    d_f['Family_mem_with_ASD'] = lab.fit_transform(d_f['Family_mem_with_ASD'])\n",
    "    d_f['Who completed the test'] = lab.fit_transform(d_f['Who completed the test'])\n",
    "    #d_f['Class/ASD Traits '] = lab.fit_transform(d_f['Class/ASD Traits '])\n",
    "    \n",
    "    c_c = ['Ethnicity', 'Who completed the test']\n",
    "    me = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "    me.fit(d_f[c_c])\n",
    "    df_new_ = pd.concat([d_f.drop(c_c, 1), pd.DataFrame(myEncoder.transform(d_f[c_c]))], axis=1).reindex()\n",
    "    \n",
    "    return df_new_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results(df_, iput_, model):\n",
    "    \"\"\"\n",
    "    returns the result of the given input\n",
    "    \"\"\"\n",
    "    columns_n = df_.columns[:-1]\n",
    "    inp_df = pd.DataFrame([iput_])\n",
    "    inp_df.columns = columns_n\n",
    "    ch_c = pre_pd(inp_df)\n",
    "    output = model.predict(ch_c)\n",
    "    if output == 0:\n",
    "        print('NO')\n",
    "    else:\n",
    "        print('YES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YES\n"
     ]
    }
   ],
   "source": [
    "results(df, inp_, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
